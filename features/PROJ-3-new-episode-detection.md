# PROJ-3: New Episode Detection

## Status: üîµ Planned

## Abh√§ngigkeiten
- **Ben√∂tigt:** PROJ-2 (Podcast Subscription Management) - Abonnierte Podcasts m√ºssen existieren

## √úbersicht
Automatisierter Cronjob (st√ºndlich) pr√ºft alle abonnierten Podcast-RSS-Feeds auf neue Episoden. Neue Episoden werden in DB gespeichert und f√ºr Transkription vorbereitet.

## User Stories

### Als System m√∂chte ich neue Episodes automatisch erkennen
- Als **System** m√∂chte ich st√ºndlich alle Podcast-RSS-Feeds pr√ºfen, um neue Episoden zu finden
- Als **System** m√∂chte ich nur wirklich neue Episoden speichern, um Duplikate zu vermeiden
- Als **System** m√∂chte ich Episode-Metadaten (Titel, Audio-URL, Dauer, Publish-Date) speichern, um sie sp√§ter zu verarbeiten

### Als User m√∂chte ich √ºber Fehler informiert werden
- Als **User** m√∂chte ich benachrichtigt werden, wenn ein Podcast-Feed nicht mehr erreichbar ist
- Als **User** m√∂chte ich benachrichtigt werden, wenn eine Episode nicht verarbeitet werden konnte

## Acceptance Criteria

### Cronjob Setup
- [ ] Cronjob l√§uft st√ºndlich (z.B. via Vercel Cron Jobs oder GitHub Actions)
- [ ] Cronjob holt alle Podcast-Abos aus DB (`SELECT * FROM podcast_subscriptions`)
- [ ] F√ºr jeden Podcast: RSS-Feed fetchen und parsen

### Episode Detection
- [ ] Jeder RSS-Feed wird auf neue `<item>` Eintr√§ge gepr√ºft
- [ ] F√ºr jede Episode werden folgende Daten extrahiert:
  - Episode-Titel (`item.title`)
  - Audio-URL (`item.enclosure.url`)
  - Publish-Date (`item.pubDate`)
  - Dauer (`item.itunes.duration`, optional)
  - Beschreibung (`item.description`, optional)
  - GUID (`item.guid` - eindeutige Episode-ID)
- [ ] Duplikat-Check: Episode mit gleichem GUID existiert bereits? ‚Üí Skip
- [ ] Neue Episode wird in DB gespeichert (`episodes` Tabelle)
- [ ] Status der neuen Episode: `pending_transcription`

### Error Handling
- [ ] Wenn RSS-Feed nicht erreichbar (Timeout, 404): Log Error, skip diesen Feed
- [ ] Wenn RSS-Feed invalid ist: Log Error, skip diesen Feed
- [ ] Bei 3 aufeinanderfolgenden Fehlern f√ºr einen Feed: User benachrichtigen (Email)
- [ ] Cronjob-Execution wird geloggt (Success/Failure, Anzahl neuer Episodes)

### Performance
- [ ] Cronjob verarbeitet max. 100 Feeds pro Run (Paginierung bei mehr Feeds)
- [ ] Timeout pro Feed: 10 Sekunden
- [ ] Gesamte Cronjob-Execution: < 5 Minuten

## Edge Cases

### Was passiert wenn...?

#### RSS-Feed ist tempor√§r nicht erreichbar
- **Szenario:** Podcast-Server ist f√ºr 2 Stunden down
- **Verhalten:** Error wird geloggt, Feed wird beim n√§chsten Cronjob (1h sp√§ter) erneut gepr√ºft
- **Kein Alert:** Erst nach 3 aufeinanderfolgenden Fehlern User benachrichtigen

#### RSS-Feed hat 100+ Episodes
- **Szenario:** Neues Feed-Abo mit vielen alten Episodes
- **Verhalten:** Nur Episodes der letzten 30 Tage als "neu" behandeln (Filter: `pubDate > NOW() - 30 days`)
- **Grund:** Vermeidet Transkription von hunderten alter Episodes

#### Episode hat keine Audio-URL (kein enclosure)
- **Szenario:** RSS-Feed item hat kein `<enclosure>` Tag
- **Verhalten:** Episode wird NICHT gespeichert (Log Warning: "Episode has no audio file")

#### Episode GUID ist leer oder fehlt
- **Szenario:** RSS-Feed hat kein `<guid>` Tag
- **Verhalten:** Fallback: Generiere GUID aus `feed_url + episode_title + pubDate` (Hash)
- **Grund:** GUID ist essentiell f√ºr Duplikat-Check

#### Zwei User abonnieren denselben Podcast
- **Szenario:** User A und User B haben beide "Podcast X" abonniert
- **Verhalten:** Episode wird zweimal gespeichert (einmal pro User-Subscription)
- **Grund:** Jede Episode ist user-spezifisch (f√ºr Newsletter-Generierung)
- **Schema:** `episodes` Tabelle hat `subscription_id` (nicht `podcast_id`)

#### Episode Publish-Date ist in der Zukunft
- **Szenario:** Podcast setzt `pubDate` auf morgiges Datum (geplante Episode)
- **Verhalten:** Episode wird NICHT gespeichert (Filter: `pubDate <= NOW()`)

#### Podcast ver√∂ffentlicht 10 Episodes gleichzeitig
- **Szenario:** Backlog-Release oder Staffel-Drop
- **Verhalten:** Alle neuen Episodes werden gespeichert und verarbeitet
- **Limit:** Max. 50 neue Episodes pro Feed pro Run (Schutz vor Spam)

#### User entfernt Podcast-Abo w√§hrend Cronjob l√§uft
- **Szenario:** Subscription wird gel√∂scht, w√§hrend Feed gecheckt wird
- **Verhalten:** Foreign Key Constraint verhindert Episode-Insert ‚Üí Skip, kein Error

#### Audio-URL ist sehr gro√ü (5GB+ File)
- **Szenario:** Episode ist extrem lang oder hochaufl√∂send
- **Verhalten:** In PROJ-3 wird nur URL gespeichert, keine Validierung
- **Hinweis:** Download + Size-Check passiert in PROJ-4 (Transcription)

## Technische Anforderungen

### Supabase Schema: `episodes`
```sql
CREATE TABLE episodes (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  subscription_id UUID NOT NULL REFERENCES podcast_subscriptions(id) ON DELETE CASCADE,
  guid TEXT NOT NULL, -- Episode unique identifier
  title TEXT NOT NULL,
  description TEXT,
  audio_url TEXT NOT NULL,
  duration_seconds INT, -- optional
  published_at TIMESTAMPTZ NOT NULL,
  status TEXT DEFAULT 'pending_transcription', -- pending_transcription, transcribing, transcribed, failed, newsletter_sent
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(subscription_id, guid) -- Verhindert Duplikate pro Subscription
);

-- Index f√ºr schnelle Status-Queries
CREATE INDEX idx_episodes_status ON episodes(status);
CREATE INDEX idx_episodes_published_at ON episodes(published_at DESC);

-- RLS Policies
ALTER TABLE episodes ENABLE ROW LEVEL SECURITY;

-- User kann nur Episodes seiner Subscriptions sehen
CREATE POLICY "Users can view own episodes"
  ON episodes FOR SELECT
  USING (
    EXISTS (
      SELECT 1 FROM podcast_subscriptions
      WHERE podcast_subscriptions.id = episodes.subscription_id
      AND podcast_subscriptions.user_id = auth.uid()
    )
  );
```

### Supabase Schema: `feed_check_logs` (Error Tracking)
```sql
CREATE TABLE feed_check_logs (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  subscription_id UUID NOT NULL REFERENCES podcast_subscriptions(id) ON DELETE CASCADE,
  status TEXT NOT NULL, -- success, error
  error_message TEXT,
  checked_at TIMESTAMPTZ DEFAULT NOW()
);

-- Index f√ºr Recent Errors Query
CREATE INDEX idx_feed_check_logs_subscription ON feed_check_logs(subscription_id, checked_at DESC);
```

### Cronjob Implementation
- **Option 1 (Recommended):** Vercel Cron Jobs (`vercel.json` + API Route)
  - `vercel.json`: `"cron": ["0 * * * *"]` (every hour)
  - API Route: `/api/cron/check-new-episodes`
- **Option 2:** GitHub Actions Workflow (hourly schedule)
- **Option 3:** External Service (Railway Cron, Render Cron)

### RSS Parsing
- Library: `rss-parser` (gleiche wie PROJ-2)
- Parse Episode Fields:
  - `item.title` ‚Üí `title`
  - `item.guid` ‚Üí `guid` (fallback: hash von `title + pubDate`)
  - `item.enclosure.url` ‚Üí `audio_url`
  - `item.pubDate` ‚Üí `published_at`
  - `item.itunes.duration` ‚Üí `duration_seconds` (convert to seconds)
  - `item.description` ‚Üí `description`

### API Route: `/api/cron/check-new-episodes`
- **Method:** GET (mit Vercel Cron) oder POST
- **Auth:** Vercel Cron Secret Header (`x-vercel-cron-secret`)
- **Flow:**
  1. Fetch alle Subscriptions: `SELECT * FROM podcast_subscriptions`
  2. F√ºr jede Subscription:
     - Fetch RSS Feed
     - Parse Items
     - Filter: `pubDate > NOW() - 30 days` UND `pubDate <= NOW()`
     - Duplikat-Check: `guid` bereits in `episodes`?
     - Insert neue Episodes mit Status `pending_transcription`
     - Log Success/Error in `feed_check_logs`
  3. Return: `{ success: true, newEpisodes: 42, errors: 2 }`

### Performance
- Parallel Processing: Max. 10 Feeds gleichzeitig (Promise.all mit Chunk-Verarbeitung)
- Timeout pro Feed: 10 Sekunden
- Gesamte Execution: < 5 Minuten (Vercel Serverless Function Limit: 10min)

### Error Notification Logic
- Query last 3 logs per subscription: `SELECT * FROM feed_check_logs WHERE subscription_id = X ORDER BY checked_at DESC LIMIT 3`
- Wenn alle 3 `status = 'error'`: Trigger Email an User
- Email enth√§lt: Podcast-Titel, Error Message, Empfehlung (Feed-URL pr√ºfen)

## Nice-to-Have (nicht f√ºr MVP)
- Dashboard f√ºr User: "Letzte gepr√ºfte Episodes" (Feed-Check-Historie)
- Retry-Mechanismus f√ºr failed Feeds (exponential backoff)
- Webhook-Support (statt Polling): Podcast-Hoster benachrichtigt bei neuer Episode
- Custom Check-Intervalle pro Podcast (t√§glich, 6h, 12h)
- Health-Check Dashboard f√ºr Admins (alle Feeds, Success-Rate)

## Tech-Design (Solution Architect)

### System-Komponenten

```
Automatisierter Cronjob (st√ºndlich)
‚îú‚îÄ‚îÄ Timer (jede Stunde ausgel√∂st)
‚îÇ
‚îú‚îÄ‚îÄ Feed-Checker (Hauptlogik)
‚îÇ   ‚îú‚îÄ‚îÄ Hole alle Podcast-Abos aus Datenbank
‚îÇ   ‚îú‚îÄ‚îÄ F√ºr jeden Podcast:
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Lade RSS-Feed von URL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Parse alle Episode-Eintr√§ge
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Filtere neue Episodes (nicht √§lter als 30 Tage)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Duplikat-Check (schon in Datenbank?)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Speichere neue Episodes
‚îÇ   ‚îî‚îÄ‚îÄ Logge Erfolge und Fehler
‚îÇ
‚îî‚îÄ‚îÄ Error-Handler
    ‚îú‚îÄ‚îÄ Z√§hle Fehler pro Feed (max. 3 Versuche)
    ‚îî‚îÄ‚îÄ Sende User-Email bei 3 aufeinanderfolgenden Fehlern
```

**Keine User-sichtbare UI** - L√§uft komplett im Hintergrund!

### Daten-Model

**Episode hat:**
- Eindeutige Episode-ID (GUID aus RSS-Feed)
- Episode-Titel
- Audio-Datei URL (zum MP3/M4A-File)
- Ver√∂ffentlichungs-Datum
- Dauer (optional, in Sekunden)
- Beschreibung (optional)
- Status ("wartet auf Transkription", "fertig", etc.)
- Zugeh√∂rigkeit zu Podcast-Abo

**Gespeichert in:** Supabase Datenbank (Tabelle: `episodes`)

**Error-Log hat:**
- Feed-URL die fehlgeschlagen ist
- Fehler-Nachricht
- Zeitstempel
- Zugeh√∂rigkeit zu Podcast-Abo

**Gespeichert in:** Supabase Datenbank (Tabelle: `feed_check_logs`)

### Tech-Entscheidungen

**Warum st√ºndlicher Cronjob?**
- Balance zwischen Aktualit√§t und Server-Last
- Podcasts erscheinen selten h√§ufiger als st√ºndlich
- Vercel erlaubt kostenlose Cron Jobs (jede Stunde)

**Warum 30-Tage Filter?**
- Verhindert Transkription von hunderten alter Episodes
- Neu abonnierte Podcasts haben oft 100+ alte Episodes im Feed
- Reduziert Kosten (Whisper API kostet pro Minute Audio)
- 30 Tage = ~4-8 neue Episodes pro Podcast (realistisch)

**Warum GUID als Duplikat-Check?**
- GUID ist eindeutige Episode-ID im RSS-Standard
- Verl√§sslicher als Titel-Vergleich (Titel k√∂nnen sich √§ndern)
- RSS-Standard garantiert GUID-Einzigartigkeit

**Warum 3 Fehler-Versuche?**
- Tempor√§re Server-Ausf√§lle sollten nicht sofort User benachrichtigen
- Nach 3 Stunden (3 aufeinanderfolgende Checks) ist es wahrscheinlich ein echtes Problem
- User wird informiert und kann Feed-URL pr√ºfen

**Warum nur neue Episodes speichern (nicht alle)?**
- Spart Speicherplatz
- User interessieren sich nur f√ºr neue Inhalte
- Alte Episodes sind nicht mehr relevant

**Warum Vercel Cron Jobs?**
- Bereits in Next.js integriert (keine zus√§tzliche Infrastruktur)
- Kostenlos im Hobby-Plan
- Einfaches Setup (nur JSON-Konfiguration)

### Dependencies

**Ben√∂tigte Packages:**
- `rss-parser` (gleiche Library wie PROJ-2)
- Vercel Cron Jobs (keine Installation n√∂tig, Teil von Next.js Deployment)

**Backend-Logik:**
- API Route f√ºr Cronjob (`/api/cron/check-new-episodes`)
- Supabase Client f√ºr Datenbank-Zugriff

### System-Workflow

**Jede Stunde passiert:**

1. **Cronjob startet** (triggert API Route)

2. **F√ºr jeden abonnierten Podcast:**
   - Lade RSS-Feed von gespeicherter URL
   - Parse alle Episode-Eintr√§ge (XML ‚Üí JavaScript-Objekt)
   - Filtere nur Episodes der letzten 30 Tage
   - Pr√ºfe: Ist Episode schon in Datenbank? (GUID-Check)
   - Falls neu: Speichere Episode mit Status "pending_transcription"

3. **Error-Handling:**
   - Feed nicht erreichbar ‚Üí Log Error, weiter mit n√§chstem Feed
   - Feed invalid ‚Üí Log Error, weiter mit n√§chstem Feed
   - Nach 3 aufeinanderfolgenden Fehlern ‚Üí Email an User

4. **Cronjob endet** (bis n√§chste Stunde)

**User merkt nichts davon** - l√§uft komplett im Hintergrund!

### Backend-API

**Endpoint:**
- `GET /api/cron/check-new-episodes` (von Vercel Cron ausgel√∂st)

**Sicherheit:**
- Nur von Vercel Cron aufrufbar (Secret-Header-Check)
- User k√∂nnen diesen Endpoint NICHT direkt aufrufen

### Vercel Cron Konfiguration

**In `vercel.json`:**
```
Zeitplan: Jede Stunde (z.B. 00:00, 01:00, 02:00, ...)
Endpoint: /api/cron/check-new-episodes
```

**Keine zus√§tzliche Infrastruktur n√∂tig** (Vercel handled alles)

### User-Benachrichtigung

**Email bei Fehler (nach 3 Versuchen):**
- Betreff: "Podcast-Feed konnte nicht geladen werden"
- Inhalt: Welcher Podcast, welcher Fehler, was User tun kann
- Nur bei permanenten Fehlern (nicht bei tempor√§ren)

## Notizen f√ºr Entwickler
- Vercel Cron Jobs sind ideal f√ºr MVP (kein externer Service n√∂tig)
- `rss-parser` ist sehr zuverl√§ssig, aber parst manchmal `itunes:duration` nicht korrekt ‚Üí Fallback-Logik implementieren
- 30-Tage Filter ist wichtig: Verhindert Transkription von hunderten alten Episodes bei neuem Abo
- User-Benachrichtigung bei Errors ist wichtig: User wissen sonst nicht, warum keine Newsletter kommen
